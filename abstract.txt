Learning a complex system is a challenging task. In the Turbulence field, it is rarely possible to have access to DNS and large datasets.
That is one of the main reasons that lead to the development of simplified models of the Navier-Stokes equations. 
We are interested in the one known as Shell Models, which has a tractable dimension, and they share with NS fundamental aspects of Turbulence from Kolmogorov Scaling (K41) to Intermittency.
The standard approach to training a Recurrent Neural Network (LSTM) consists in giving the model each time the points in training data and minimising the loss between the training data and the generated. 
This creates a discrepancy between what the model learns and what the model has to be able to do. Indeed the model should be able to generate new points starting from an initial condition. We propose a new training method. 
Each time we give as input to the model the previous generated point. This method shows an increase in performances.
